{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# rolling minmax scaling 함수 (window=24)\n",
    "def rolling_minmax_scale(series, window=12):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "# binning 및 one-hot 인코딩 함수 (결과를 정수 0,1로)\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "##############################################\n",
    "# Diffusion 모델을 위한 Dataset 정의\n",
    "##############################################\n",
    "class DiffusionTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, input_data, target_data, lookback=12):\n",
    "        self.input_data = input_data.values\n",
    "        self.target_data = target_data.values\n",
    "        self.lookback = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.lookback\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 조건 데이터: lookback window\n",
    "        x = self.input_data[idx: idx + self.lookback, :]\n",
    "        # 타깃: close_target 값을 이용해 상승이면 1, 하락이면 0으로 설정 (float형)\n",
    "        y = self.target_data[idx + self.lookback, 0]\n",
    "        y_prev = self.target_data[idx + self.lookback - 1, 0]\n",
    "        label = 1.0 if y > y_prev else 0.0\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor([label], dtype=torch.float32)\n",
    "\n",
    "##############################################\n",
    "# Condition Encoder: 시계열 window를 벡터로 인코딩\n",
    "##############################################\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim):\n",
    "        super(ConditionEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim * lookback, condition_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(condition_dim, condition_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch, lookback, input_dim]\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "##############################################\n",
    "# DiffusionClassifier: diffusion process를 통한 노이즈 예측 모델\n",
    "##############################################\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim=128, num_timesteps=100, hidden_dim=128):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        # diffusion 스케줄 (선형 beta schedule)\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        \n",
    "        # 조건 인코더: 시계열 데이터를 조건으로 임베딩\n",
    "        self.condition_encoder = ConditionEncoder(input_dim, lookback, condition_dim)\n",
    "        # timestep 임베딩\n",
    "        self.time_embedding = nn.Embedding(num_timesteps, hidden_dim)\n",
    "        # 노이즈 예측 네트워크: 입력은 [y_noisy, condition, timestep embedding]\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 + condition_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_condition, y_noisy, t):\n",
    "        # x_condition: [batch, lookback, input_dim]\n",
    "        # y_noisy: [batch, 1] - 노이즈가 추가된 타깃\n",
    "        # t: [batch] - timestep 인덱스\n",
    "        cond = self.condition_encoder(x_condition)           # [batch, condition_dim]\n",
    "        t_emb = self.time_embedding(t)                         # [batch, hidden_dim]\n",
    "        inp = torch.cat([y_noisy, cond, t_emb], dim=1)          # [batch, 1+condition_dim+hidden_dim]\n",
    "        predicted_noise = self.model(inp)                      # [batch, 1]\n",
    "        return predicted_noise\n",
    "    \n",
    "    def sample(self, x_condition, device):\n",
    "        \"\"\"\n",
    "        reverse diffusion 과정을 통해 조건 x_condition에 대해 예측값을 샘플링\n",
    "        최종 출력은 continuous 값으로, 임계값 0.5로 분류 가능함.\n",
    "        \"\"\"\n",
    "        batch_size = x_condition.size(0)\n",
    "        # 초기 y: 정규분포 노이즈\n",
    "        y = torch.randn(batch_size, 1, device=device)\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x_condition, y, t_tensor)\n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            # DDPM 업데이트: 간단화된 형태\n",
    "            y = (1 / torch.sqrt(alpha)) * (y - (beta / torch.sqrt(1 - alpha_cumprod)) * predicted_noise)\n",
    "            # t > 0이면 약간의 노이즈 추가\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(y)\n",
    "                y = y + torch.sqrt(beta) * noise\n",
    "        return y\n",
    "\n",
    "##############################################\n",
    "# Diffusion 모델 학습 및 평가 함수\n",
    "##############################################\n",
    "def train_diffusion_model(model, dataloader, num_epochs, device, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)  # [batch, lookback, input_dim]\n",
    "            y = y.to(device)  # [batch, 1] (0.0 or 1.0)\n",
    "            batch_size = x.size(0)\n",
    "            # 각 배치마다 timestep t를 균등 샘플링\n",
    "            t = torch.randint(0, model.num_timesteps, (batch_size,), device=device).long()\n",
    "            # 해당 timestep에 따른 누적 알파값\n",
    "            alphas_cumprod_t = model.alphas_cumprod[t].view(batch_size, 1)\n",
    "            # 노이즈 샘플링\n",
    "            noise = torch.randn_like(y)\n",
    "            # y_noisy = sqrt(alpha_cumprod)*y + sqrt(1-alpha_cumprod)*noise\n",
    "            y_noisy = torch.sqrt(alphas_cumprod_t) * y + torch.sqrt(1 - alphas_cumprod_t) * noise\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise = model(x, y_noisy, t)\n",
    "            loss = mse_loss(predicted_noise, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "def evaluate_diffusion_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # reverse diffusion 과정을 통해 예측값 샘플링\n",
    "            y_sampled = model.sample(x, device)\n",
    "            # 0.5 기준으로 분류\n",
    "            y_pred = (y_sampled >= 0.5).float()\n",
    "            correct += (y_pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Evaluation Accuracy: {acc:.4f}\")\n",
    "    return acc\n",
    "\n",
    "##############################################\n",
    "# 데이터 로드 및 전처리 (OHLC 4개 데이터 사용)\n",
    "##############################################\n",
    "data = pd.read_csv(\"ETH_upbit_KRW_min5_0309.csv\", index_col=0)\n",
    "data = data[['open', 'high', 'low', 'close']]\n",
    "data.index = pd.to_datetime(data.index)\n",
    "\n",
    "ohlc_features = ['open', 'high', 'low', 'close']\n",
    "for feature in ohlc_features:\n",
    "    data[feature] = rolling_minmax_scale(data[feature], window=12)\n",
    "\n",
    "data = bin_and_encode(data, ohlc_features, bins=100, drop_original=True)\n",
    "# 타깃은 원본 close 값 사용 (실험 목적)\n",
    "data['close_target'] = data['close']\n",
    "data = data.dropna()\n",
    "\n",
    "# 최종 입력: _Bin_ 접미사가 있는 열들만 사용\n",
    "final_input_columns = [col for col in data.columns if '_Bin_' in col]\n",
    "final_target_column = ['close_target']\n",
    "\n",
    "data_input = data[final_input_columns]\n",
    "data_target = data[final_target_column]\n",
    "\n",
    "##############################################\n",
    "# 실험 실행: Diffusion Model 기반 주가 상승/하락 예측\n",
    "##############################################\n",
    "def train_and_evaluate_diffusion(data, num_experiments=16, lookback=12, num_epochs=10):\n",
    "    final_input_columns = [col for col in data.columns if '_Bin_' in col]\n",
    "    target_cols = ['close_target']\n",
    "    \n",
    "    data_input = data[final_input_columns]\n",
    "    data_target = data[target_cols]\n",
    "    \n",
    "    data_input = data_input.apply(pd.to_numeric).astype(np.float32)\n",
    "    data_target = data_target.apply(pd.to_numeric).astype(np.float32)\n",
    "    \n",
    "    step_size = 32000\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    val_acc_list = []\n",
    "    test_acc_list = []\n",
    "    \n",
    "    for exp in range(num_experiments):\n",
    "        train_start = exp * step_size\n",
    "        train_end = train_start + step_size * 8\n",
    "        val_end = train_end + step_size\n",
    "        test_end = val_end + step_size\n",
    "        if test_end > len(data_input):\n",
    "            break\n",
    "        print(f\"\\nExperiment {exp}: 데이터 구간 [{train_start}:{test_end}]\")\n",
    "        \n",
    "        train_input = data_input.iloc[train_start:train_end]\n",
    "        train_target = data_target.iloc[train_start:train_end]\n",
    "        val_input = data_input.iloc[train_end:val_end]\n",
    "        val_target = data_target.iloc[train_end:val_end]\n",
    "        test_input = data_input.iloc[val_end:test_end]\n",
    "        test_target = data_target.iloc[val_end:test_end]\n",
    "        \n",
    "        train_dataset = DiffusionTimeSeriesDataset(train_input, train_target, lookback=lookback)\n",
    "        val_dataset = DiffusionTimeSeriesDataset(val_input, val_target, lookback=lookback)\n",
    "        test_dataset = DiffusionTimeSeriesDataset(test_input, test_target, lookback=lookback)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        input_dim = train_input.shape[1]\n",
    "        model = DiffusionClassifier(input_dim=input_dim, lookback=lookback, \n",
    "                                    condition_dim=128, num_timesteps=100, hidden_dim=128).to(device)\n",
    "        model_path = f\"diffusion_model_experiment_{exp}.pth\"\n",
    "        if exp > 0:\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(f\"diffusion_model_experiment_{exp - 1}.pth\"))\n",
    "                print(f\"Loaded model from experiment {exp - 1} for fine-tuning.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Model file for experiment {exp - 1} not found. Starting fresh training.\")\n",
    "        \n",
    "        print(f\"Experiment {exp}: Training Diffusion Model\")\n",
    "        train_diffusion_model(model, train_loader, num_epochs, device, lr=1e-4)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved model for experiment {exp}.\")\n",
    "        \n",
    "        print(\"Validation Evaluation:\")\n",
    "        val_acc = evaluate_diffusion_model(model, val_loader, device)\n",
    "        val_acc_list.append(val_acc)\n",
    "        \n",
    "        print(\"Test Evaluation:\")\n",
    "        test_acc = evaluate_diffusion_model(model, test_loader, device)\n",
    "        test_acc_list.append(test_acc)\n",
    "    \n",
    "    if val_acc_list:\n",
    "        avg_val_acc = sum(val_acc_list) / len(val_acc_list)\n",
    "        avg_test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "        print(f\"\\nFinal Average Validation Accuracy: {avg_val_acc:.4f}\")\n",
    "        print(f\"Final Average Test Accuracy: {avg_test_acc:.4f}\")\n",
    "    else:\n",
    "        print(\"실험이 한 번도 실행되지 않았습니다.\")\n",
    "\n",
    "# 최종적으로 Diffusion Model 실험 실행\n",
    "train_and_evaluate_diffusion(data, num_experiments=15, lookback=12, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyupbit\n",
    "import requests\n",
    "\n",
    "# --- LINE Notify 설정 ---\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = \"rlMIJRZSatEVj5MLBSqC0iVVRIM7trYKqVbwizh7gUL\"\n",
    "def send_line_notification(message):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"message\": message}\n",
    "    response = requests.post(TARGET_URL, headers=headers, data=data)\n",
    "    return response\n",
    "\n",
    "def notify(message):\n",
    "    print(message)\n",
    "    send_line_notification(message)\n",
    "\n",
    "# --- 전처리 함수 ---\n",
    "def rolling_minmax_scale(series, window=24):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "# --- Diffusion Model 구성 ---\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim):\n",
    "        super(ConditionEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim * lookback, condition_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(condition_dim, condition_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch, lookback, input_dim]\n",
    "        batch_size = x.size(0)\n",
    "        x = x.contiguous().view(batch_size, -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim=128, num_timesteps=100, hidden_dim=128):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        # diffusion 스케줄 (선형 beta schedule)\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        \n",
    "        # 조건 인코더: 시계열 window를 임베딩\n",
    "        self.condition_encoder = ConditionEncoder(input_dim, lookback, condition_dim)\n",
    "        # timestep 임베딩\n",
    "        self.time_embedding = nn.Embedding(num_timesteps, hidden_dim)\n",
    "        # 노이즈 예측 네트워크\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 + condition_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_condition, y_noisy, t):\n",
    "        # x_condition: [batch, lookback, input_dim]\n",
    "        # y_noisy: [batch, 1]\n",
    "        # t: [batch]\n",
    "        cond = self.condition_encoder(x_condition)           # [batch, condition_dim]\n",
    "        t_emb = self.time_embedding(t)                         # [batch, hidden_dim]\n",
    "        inp = torch.cat([y_noisy, cond, t_emb], dim=1)          # [batch, 1 + condition_dim + hidden_dim]\n",
    "        predicted_noise = self.model(inp)                      # [batch, 1]\n",
    "        return predicted_noise\n",
    "    \n",
    "    def sample(self, x_condition, device):\n",
    "        \"\"\"\n",
    "        reverse diffusion 과정을 통해 조건 x_condition에 대해 예측값을 샘플링.\n",
    "        최종 출력은 continuous 값으로, 임계값 0.5를 기준으로 상승(1) 또는 하락(0) 결정.\n",
    "        \"\"\"\n",
    "        batch_size = x_condition.size(0)\n",
    "        y = torch.randn(batch_size, 1, device=device)  # 초기 y: 정규분포 노이즈\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x_condition, y, t_tensor)\n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            y = (1 / torch.sqrt(alpha)) * (y - (beta / torch.sqrt(1 - alpha_cumprod)) * predicted_noise)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(y)\n",
    "                y = y + torch.sqrt(beta) * noise\n",
    "        return y\n",
    "\n",
    "# --- 모델 로드 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# OHLC 4개 feature를 100구간으로 binning했으므로 입력 차원은 4*100 = 400\n",
    "input_dim = 400\n",
    "lookback = 24\n",
    "model = DiffusionClassifier(input_dim=input_dim, lookback=lookback, condition_dim=128, num_timesteps=100, hidden_dim=128).to(device)\n",
    "model_path = \"diffusion_model_experiment_14_24.pth\"  # 실제 학습된 모델 파일 경로로 수정\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# --- pyupbit API 설정 ---\n",
    "access = \"x03uKM3uyZ9RNDBHLxauEaeI6X8pdKQq8rHG2wvx\"\n",
    "secret = \"e9UyPqJBjCvNDxCmtx7bdPaHtAEgw2Ftxu3UpuJc\"\n",
    "upbit = pyupbit.Upbit(access, secret)\n",
    "ticker = \"KRW-ETH\"  # 거래할 코인 티커\n",
    "\n",
    "# --- 예측 함수 ---\n",
    "def get_model_prediction():\n",
    "    \"\"\"\n",
    "    pyupbit로 최근 15개의 5분봉 데이터를 가져와 전처리한 후,\n",
    "    마지막 lookback(6) 봉을 diffusion model의 조건으로 사용하여\n",
    "    reverse diffusion sampling을 통해 다음 5분봉 상승(1)/하락(0) 예측을 반환.\n",
    "    \"\"\"\n",
    "    df = pyupbit.get_ohlcv(ticker, interval=\"minute5\", count=50)\n",
    "    if df is None or len(df) < lookback:\n",
    "        notify(\"예측에 충분한 데이터가 없습니다.\")\n",
    "        return None\n",
    "    ohlc_features = ['open', 'high', 'low', 'close']\n",
    "    for feature in ohlc_features:\n",
    "        df[feature] = rolling_minmax_scale(df[feature], window=24)\n",
    "    df_processed = bin_and_encode(df.copy(), ohlc_features, bins=100, drop_original=True)\n",
    "    final_input_columns = [col for col in df_processed.columns if '_Bin_' in col]\n",
    "    if len(df_processed) < lookback:\n",
    "        notify(\"lookback 데이터가 부족합니다.\")\n",
    "        return None\n",
    "    input_seq = df_processed[final_input_columns].iloc[-lookback:]\n",
    "    # 모델 입력 형태: [batch, seq_len, features]\n",
    "    x = torch.tensor(input_seq.values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_cont = model.sample(x, device)  # continuous output\n",
    "        notify(\"디버그: y_cont = \" + str(y_cont.item()))\n",
    "        prediction = 1 if y_cont.item() >= 0.5 else 0\n",
    "    return prediction\n",
    "\n",
    "# --- 글로벌 변수: pending_trade와 거래 통계 ---\n",
    "pending_trade = None  # 현재 진행 중인 거래 정보 저장 (없으면 None)\n",
    "stats = {\n",
    "    'total_trades': 0,\n",
    "    'win_count': 0,\n",
    "    'cumulative_return': 1.0,\n",
    "    'trade_returns': []\n",
    "}\n",
    "\n",
    "# --- 거래 실행 함수 (신규 거래 진입) ---\n",
    "def trade_decision():\n",
    "    global pending_trade\n",
    "    prediction = get_model_prediction()\n",
    "    if prediction is None:\n",
    "        return\n",
    "    entry_price = pyupbit.get_current_price(ticker)\n",
    "    if entry_price is None:\n",
    "        notify(\"현재가를 조회하지 못했습니다.\")\n",
    "        return\n",
    "    if prediction == 1:\n",
    "        # 상승 예측: KRW 잔고의 50% 사용하여 매수 → 구매 코인 수 = (거래금액 / 진입가)\n",
    "        krw_balance = upbit.get_balance(\"KRW\")\n",
    "        if krw_balance is None or krw_balance < 5000:\n",
    "            notify(\"매수할 충분한 KRW 잔고가 없습니다.\")\n",
    "            return\n",
    "        trade_amount_krw = krw_balance * 0.2\n",
    "        coins_bought = trade_amount_krw / entry_price\n",
    "        notify(f\"[진입] 상승 예측: KRW 잔고의 50%({trade_amount_krw:.0f} KRW)로 매수, 진입가: {entry_price:.2f}, 구매 개수: {coins_bought:.4f} 개\")\n",
    "        upbit.buy_market_order(ticker, trade_amount_krw)  # 실제 주문 실행 (주석 해제)\n",
    "        pending_trade = {\n",
    "            'direction': prediction,  # 1: Long\n",
    "            'entry_price': entry_price,\n",
    "            'quantity': coins_bought,\n",
    "            'entry_time': pd.Timestamp.now()\n",
    "        }\n",
    "    else:\n",
    "        # 하락 예측: 보유 코인의 50% 매도\n",
    "        coin = ticker.split(\"-\")[1]\n",
    "        coin_balance = upbit.get_balance(coin)\n",
    "        if coin_balance is None or coin_balance <= 0:\n",
    "            notify(\"매도할 보유 코인이 없습니다.\")\n",
    "            return\n",
    "        trade_amount_coins = coin_balance * 0.2\n",
    "        notify(f\"[진입] 하락 예측: 보유 코인의 50%({trade_amount_coins:.4f} 개) 매도, 진입가: {entry_price:.2f}\")\n",
    "        upbit.sell_market_order(ticker, trade_amount_coins)  # 실제 주문 실행 (주석 해제)\n",
    "        pending_trade = {\n",
    "            'direction': prediction,  # 0: Short\n",
    "            'entry_price': entry_price,\n",
    "            'quantity': trade_amount_coins,\n",
    "            'entry_time': pd.Timestamp.now()\n",
    "        }\n",
    "\n",
    "# --- 거래 결과 처리 함수 (청산 시점에서 거래 결과 계산) ---\n",
    "def process_pending_trade():\n",
    "    global pending_trade, stats\n",
    "    if pending_trade is None:\n",
    "        return\n",
    "    exit_price = pyupbit.get_current_price(ticker)\n",
    "    if exit_price is None:\n",
    "        notify(\"청산 가격을 조회하지 못했습니다.\")\n",
    "        return\n",
    "    direction = pending_trade['direction']\n",
    "    entry_price = pending_trade['entry_price']\n",
    "    fee = 0.0005  # 0.05%\n",
    "    if direction == 1:  # Long 거래: 상승 예측\n",
    "        fraction = 0.2\n",
    "        effective_factor = (exit_price * (1 - fee)) / (entry_price * (1 + fee))\n",
    "        trade_return = 1 + fraction * (effective_factor - 1)\n",
    "        trade_type = \"Long\"\n",
    "        # hit/miss 판정: Long 거래는 exit_price가 entry_price보다 높아야 hit\n",
    "        outcome = \"Hit\" if exit_price > entry_price else \"Miss\"\n",
    "    else:  # Short 거래: 하락 예측\n",
    "        fraction = 0.2\n",
    "        effective_factor = (entry_price * (1 - fee)) / (exit_price * (1 + fee))\n",
    "        trade_return = 1 + fraction * (effective_factor - 1)\n",
    "        trade_type = \"Short\"\n",
    "        # hit/miss 판정: Short 거래는 exit_price가 entry_price보다 같거나 낮아야 hit (보합 포함)\n",
    "        outcome = \"Hit\" if exit_price <= entry_price else \"Miss\"\n",
    "    \n",
    "    stats['total_trades'] += 1\n",
    "    if outcome == \"Hit\":\n",
    "        stats['win_count'] += 1\n",
    "    stats['cumulative_return'] *= trade_return\n",
    "    stats['trade_returns'].append(trade_return)\n",
    "    quantity = pending_trade.get('quantity', 0)\n",
    "    notify(f\"[청산] {trade_type} 거래 - 진입가: {entry_price:.2f}, 청산가: {exit_price:.2f}, 거래 개수: {quantity:.4f} 개, 거래 수익률: {trade_return:.4f} ({outcome})\")\n",
    "    hit_ratio = stats['win_count'] / stats['total_trades'] if stats['total_trades'] > 0 else 0\n",
    "    notify(f\"거래 횟수: {stats['total_trades']}, Hit Ratio: {hit_ratio:.2%}, 누적 수익률: {stats['cumulative_return']:.4f}\\n\")\n",
    "    pending_trade = None\n",
    "\n",
    "# --- 메인 루프: 새로운 5분봉이 생성될 때마다 업데이트 ---\n",
    "last_candle_time = None\n",
    "while True:\n",
    "    try:\n",
    "        df = pyupbit.get_ohlcv(ticker, interval=\"minute5\", count=1)\n",
    "        if df is not None and not df.empty:\n",
    "            current_candle_time = df.index[-1]\n",
    "            if last_candle_time is None or current_candle_time > last_candle_time:\n",
    "                if pending_trade is not None:\n",
    "                    process_pending_trade()\n",
    "                notify(f\"새로운 5분봉 생성: {current_candle_time}\")\n",
    "                trade_decision()\n",
    "                last_candle_time = current_candle_time\n",
    "        else:\n",
    "            notify(\"최신 5분봉 데이터를 불러오지 못했습니다.\")\n",
    "    except Exception as e:\n",
    "        notify(f\"에러 발생: {e}\")\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
