{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from math import sqrt\n",
    "\n",
    "##############################################\n",
    "# 데이터 전처리: rolling minmax scaling 및 binning\n",
    "##############################################\n",
    "def rolling_minmax_scale(series, window=24):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "##############################################\n",
    "# Diffusion 모델을 위한 Dataset 정의 (회귀 + 방향 평가용)\n",
    "##############################################\n",
    "class DiffusionTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, input_data, target_data, lookback=24):\n",
    "        self.input_data = input_data.values\n",
    "        self.target_data = target_data.values  # continuous target 값 (scaled close)\n",
    "        self.lookback = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.lookback\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 조건 데이터: lookback window\n",
    "        x = self.input_data[idx: idx + self.lookback, :]\n",
    "        # 타깃: 다음 시점의 target (continuous)\n",
    "        target = self.target_data[idx + self.lookback, 0]\n",
    "        # 이전 시점의 target (분류 평가에 사용)\n",
    "        prev_target = self.target_data[idx + self.lookback - 1, 0]\n",
    "        return (torch.tensor(x, dtype=torch.float32),\n",
    "                torch.tensor([target], dtype=torch.float32),\n",
    "                torch.tensor([prev_target], dtype=torch.float32))\n",
    "\n",
    "##############################################\n",
    "# Condition Encoder: 시계열 window를 벡터로 인코딩\n",
    "##############################################\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim):\n",
    "        super(ConditionEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim * lookback, condition_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(condition_dim, condition_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "##############################################\n",
    "# DiffusionClassifier: 조건부 diffusion 모델 (회귀, 평가 시 방향 분류)\n",
    "##############################################\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim=128, num_timesteps=100, hidden_dim=128):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        \n",
    "        self.condition_encoder = ConditionEncoder(input_dim, lookback, condition_dim)\n",
    "        self.time_embedding = nn.Embedding(num_timesteps, hidden_dim)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 + condition_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_condition, y_noisy, t):\n",
    "        cond = self.condition_encoder(x_condition)\n",
    "        t_emb = self.time_embedding(t)\n",
    "        inp = torch.cat([y_noisy, cond, t_emb], dim=1)\n",
    "        predicted_noise = self.model(inp)\n",
    "        return predicted_noise\n",
    "    \n",
    "    def sample(self, x_condition, device):\n",
    "        batch_size = x_condition.size(0)\n",
    "        y = torch.randn(batch_size, 1, device=device)\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x_condition, y, t_tensor)\n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            y = (1 / torch.sqrt(alpha)) * (y - (beta / torch.sqrt(1 - alpha_cumprod)) * predicted_noise)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(y)\n",
    "                y = y + torch.sqrt(beta) * noise\n",
    "        return y\n",
    "\n",
    "##############################################\n",
    "# Diffusion 모델 학습 및 평가 함수 (회귀 + 방향 평가)\n",
    "##############################################\n",
    "def train_diffusion_model(model, dataloader, num_epochs, device, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x, y, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            t = torch.randint(0, model.num_timesteps, (batch_size,), device=device).long()\n",
    "            alphas_cumprod_t = model.alphas_cumprod[t].view(batch_size, 1)\n",
    "            noise = torch.randn_like(y)\n",
    "            y_noisy = torch.sqrt(alphas_cumprod_t) * y + torch.sqrt(1 - alphas_cumprod_t) * noise\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise = model(x, y_noisy, t)\n",
    "            loss = mse_loss(predicted_noise, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.6f}\")\n",
    "\n",
    "def evaluate_diffusion_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    total_mse = 0\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, y_prev in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_prev = y_prev.to(device)\n",
    "            y_sampled = model.sample(x, device)\n",
    "            loss = mse_loss(y_sampled, y)\n",
    "            total_mse += loss.item() * y.size(0)\n",
    "            total_samples += y.size(0)\n",
    "            # 예측된 방향: 1 if 예측값 > y_prev, 0 otherwise\n",
    "            y_pred_class = (y_sampled > y_prev).float()\n",
    "            # 실제 방향: 1 if y > y_prev, else 0\n",
    "            y_true_class = (y > y_prev).float()\n",
    "            correct += (y_pred_class == y_true_class).sum().item()\n",
    "    avg_mse = total_mse / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    print(f\"Evaluation MSE: {avg_mse:.6f}, Accuracy: {accuracy:.4f}\")\n",
    "    return avg_mse, accuracy\n",
    "\n",
    "##############################################\n",
    "# 데이터 로드 및 전처리 (OHLC 값 사용: 원본 값에 scaling 후 인코딩)\n",
    "##############################################\n",
    "data = pd.read_csv(\"ETH_upbit_KRW_min5_0309.csv\", index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data = data[['open', 'high', 'low', 'close']]\n",
    "\n",
    "# 각 OHLC에 대해 rolling minmax scaling 적용 후 새 컬럼 생성 (scaled 값)\n",
    "for feature in ['open', 'high', 'low', 'close']:\n",
    "    data[feature + '_scaled'] = rolling_minmax_scale(data[feature], window=24)\n",
    "data = data.dropna()\n",
    "\n",
    "# one-hot 인코딩: _scaled 컬럼 대상 (각 100구간 → 총 400차원)\n",
    "features_to_bin = ['open_scaled', 'high_scaled', 'low_scaled', 'close_scaled']\n",
    "data = bin_and_encode(data, features_to_bin, bins=100, drop_original=True)\n",
    "\n",
    "# 타깃: close_scaled 컬럼을 그대로 사용 (continuous regression target)\n",
    "data['close_target'] = data['close_scaled']\n",
    "data = data.dropna()\n",
    "\n",
    "# 최종 입력: '_scaled_Bin_'가 포함된 열들만 선택\n",
    "final_input_columns = [col for col in data.columns if '_scaled_Bin_' in col]\n",
    "final_target_column = ['close_target']\n",
    "\n",
    "data_input = data[final_input_columns]\n",
    "data_target = data[final_target_column]\n",
    "\n",
    "##############################################\n",
    "# 실험 실행: Diffusion Model 기반 주가 예측 (회귀 + 방향 평가)\n",
    "##############################################\n",
    "def train_and_evaluate_diffusion(data, num_experiments=16, lookback=24, num_epochs=10):\n",
    "    final_input_columns = [col for col in data.columns if '_scaled_Bin_' in col]\n",
    "    target_cols = ['close_target']\n",
    "    \n",
    "    data_input = data[final_input_columns]\n",
    "    data_target = data[target_cols]\n",
    "    \n",
    "    data_input = data_input.apply(pd.to_numeric).astype(np.float32)\n",
    "    data_target = data_target.apply(pd.to_numeric).astype(np.float32)\n",
    "    \n",
    "    step_size = 31200\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    val_mse_list = []\n",
    "    test_mse_list = []\n",
    "    val_acc_list = []\n",
    "    test_acc_list = []\n",
    "    \n",
    "    for exp in range(num_experiments):\n",
    "        train_start = exp * step_size\n",
    "        train_end = train_start + step_size * 8\n",
    "        val_end = train_end + step_size\n",
    "        test_end = val_end + step_size\n",
    "        if test_end > len(data_input):\n",
    "            break\n",
    "        print(f\"\\nExperiment {exp}: 데이터 구간 [{train_start}:{test_end}]\")\n",
    "        \n",
    "        train_input = data_input.iloc[train_start:train_end]\n",
    "        train_target = data_target.iloc[train_start:train_end]\n",
    "        val_input = data_input.iloc[train_end:val_end]\n",
    "        val_target = data_target.iloc[train_end:val_end]\n",
    "        test_input = data_input.iloc[val_end:test_end]\n",
    "        test_target = data_target.iloc[val_end:test_end]\n",
    "        \n",
    "        train_dataset = DiffusionTimeSeriesDataset(train_input, train_target, lookback=lookback)\n",
    "        val_dataset = DiffusionTimeSeriesDataset(val_input, val_target, lookback=lookback)\n",
    "        test_dataset = DiffusionTimeSeriesDataset(test_input, test_target, lookback=lookback)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        input_dim = train_input.shape[1]\n",
    "        model = DiffusionClassifier(input_dim=input_dim, lookback=lookback, \n",
    "                                    condition_dim=128, num_timesteps=100, hidden_dim=128).to(device)\n",
    "        model_path = f\"diffusion_model_experiment_{exp}.pth\"\n",
    "        if exp > 0:\n",
    "            try:\n",
    "                model.load_state_dict(torch.load(f\"diffusion_model_experiment_{exp - 1}.pth\"))\n",
    "                print(f\"Loaded model from experiment {exp - 1} for fine-tuning.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Model file for experiment {exp - 1} not found. Starting fresh training.\")\n",
    "        \n",
    "        print(f\"Experiment {exp}: Training Diffusion Model\")\n",
    "        train_diffusion_model(model, train_loader, num_epochs, device, lr=1e-4)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved model for experiment {exp}.\")\n",
    "        \n",
    "        print(\"Validation Evaluation:\")\n",
    "        val_mse, val_acc = evaluate_diffusion_model(model, val_loader, device)\n",
    "        val_mse_list.append(val_mse)\n",
    "        val_acc_list.append(val_acc)\n",
    "        \n",
    "        print(\"Test Evaluation:\")\n",
    "        test_mse, test_acc = evaluate_diffusion_model(model, test_loader, device)\n",
    "        test_mse_list.append(test_mse)\n",
    "        test_acc_list.append(test_acc)\n",
    "    \n",
    "        print(f\"Experiment {exp}: Validation MSE: {val_mse:.6f}, val_Accuracy: {val_acc:.4f}, test_Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    if val_mse_list:\n",
    "        avg_val_mse = sum(val_mse_list) / len(val_mse_list)\n",
    "        avg_test_mse = sum(test_mse_list) / len(test_mse_list)\n",
    "        avg_val_acc = sum(val_acc_list) / len(val_acc_list)\n",
    "        avg_test_acc = sum(test_acc_list) / len(test_acc_list)\n",
    "        print(f\"\\nFinal Average Validation MSE: {avg_val_mse:.6f}\")\n",
    "        print(f\"Final Average Test MSE: {avg_test_mse:.6f}\")\n",
    "        print(f\"Final Average Val Accuracy: {avg_val_acc:.4f}\")\n",
    "        print(f\"Final Average Test Accuracy: {avg_test_acc:.4f}\")\n",
    "    else:\n",
    "        print(\"실험이 한 번도 실행되지 않았습니다.\")\n",
    "\n",
    "##############################################\n",
    "# 전체 실행 시간 측정\n",
    "##############################################\n",
    "start_time = time.time()\n",
    "train_and_evaluate_diffusion(data, num_experiments=16, lookback=24, num_epochs=10)\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "print(f\"\\n총 수행 시간: {elapsed:.2f}초\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyupbit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from math import sqrt\n",
    "\n",
    "# --- LINE Notify 설정 ---\n",
    "TARGET_URL = 'https://notify-api.line.me/api/notify'\n",
    "TOKEN = \"rlMIJRZSatEVj5MLBSqC0iVVRIM7trYKqVbwizh7gUL\"\n",
    "def send_line_notification(message):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {TOKEN}\",\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\"message\": message}\n",
    "    response = requests.post(TARGET_URL, headers=headers, data=data)\n",
    "    return response\n",
    "\n",
    "def notify(message):\n",
    "    print(message)\n",
    "    send_line_notification(message)\n",
    "    \n",
    "##############################################\n",
    "# 데이터 전처리: rolling minmax scaling 및 binning\n",
    "##############################################\n",
    "def rolling_minmax_scale(series, window=24):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "##############################################\n",
    "# Diffusion 모델을 위한 Dataset 정의 (회귀 + 방향 평가용)\n",
    "##############################################\n",
    "class DiffusionTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, input_data, target_data, lookback=24):\n",
    "        # input_data: one-hot 인코딩된 feature (예: OHLC_scaled 값에 대해 100구간 인코딩 → 총 400차원)\n",
    "        # target_data: 원본 close 값 (continuous regression target)\n",
    "        self.input_data = input_data.values\n",
    "        self.target_data = target_data.values\n",
    "        self.lookback = lookback\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data) - self.lookback\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.input_data[idx: idx + self.lookback, :]\n",
    "        target = self.target_data[idx + self.lookback, 0]       # 실제 close 값\n",
    "        prev_target = self.target_data[idx + self.lookback - 1, 0] # 이전 close 값 (평가용)\n",
    "        return (torch.tensor(x, dtype=torch.float32),\n",
    "                torch.tensor([target], dtype=torch.float32),\n",
    "                torch.tensor([prev_target], dtype=torch.float32))\n",
    "\n",
    "##############################################\n",
    "# Condition Encoder 및 DiffusionClassifier (학습/추론 모델)\n",
    "##############################################\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim):\n",
    "        super(ConditionEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim * lookback, condition_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(condition_dim, condition_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)  # 또는 x.contiguous().view(batch_size, -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim=128, num_timesteps=100, hidden_dim=128):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        \n",
    "        self.condition_encoder = ConditionEncoder(input_dim, lookback, condition_dim)\n",
    "        self.time_embedding = nn.Embedding(num_timesteps, hidden_dim)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 + condition_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_condition, y_noisy, t):\n",
    "        cond = self.condition_encoder(x_condition)\n",
    "        t_emb = self.time_embedding(t)\n",
    "        inp = torch.cat([y_noisy, cond, t_emb], dim=1)\n",
    "        predicted_noise = self.model(inp)\n",
    "        return predicted_noise\n",
    "    \n",
    "    def sample(self, x_condition, device):\n",
    "        batch_size = x_condition.size(0)\n",
    "        y = torch.randn(batch_size, 1, device=device)\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x_condition, y, t_tensor)\n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            y = (1 / torch.sqrt(alpha)) * (y - (beta / torch.sqrt(1 - alpha_cumprod)) * predicted_noise)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(y)\n",
    "                y = y + torch.sqrt(beta) * noise\n",
    "        return y\n",
    "\n",
    "##############################################\n",
    "# 학습 및 평가 함수 (회귀: MSE로 노이즈 예측하고, 평가 시 방향 hit ratio 계산)\n",
    "##############################################\n",
    "def train_diffusion_model(model, dataloader, num_epochs, device, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for x, y, _ in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            batch_size = x.size(0)\n",
    "            t = torch.randint(0, model.num_timesteps, (batch_size,), device=device).long()\n",
    "            alphas_cumprod_t = model.alphas_cumprod[t].view(batch_size, 1)\n",
    "            noise = torch.randn_like(y)\n",
    "            y_noisy = torch.sqrt(alphas_cumprod_t) * y + torch.sqrt(1 - alphas_cumprod_t) * noise\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise = model(x, y_noisy, t)\n",
    "            loss = mse_loss(predicted_noise, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader):.6f}\")\n",
    "\n",
    "def evaluate_diffusion_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    total_mse = 0\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y, y_prev in dataloader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_prev = y_prev.to(device)\n",
    "            y_sampled = model.sample(x, device)\n",
    "            loss = mse_loss(y_sampled, y)\n",
    "            total_mse += loss.item() * y.size(0)\n",
    "            total_samples += y.size(0)\n",
    "            # 방향 평가: 예측 방향 = 1 if 예측값 > 이전 target, else 0\n",
    "            y_pred_class = (y_sampled > y_prev).float()\n",
    "            y_true_class = (y > y_prev).float()\n",
    "            correct += (y_pred_class == y_true_class).sum().item()\n",
    "    avg_mse = total_mse / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    print(f\"Evaluation MSE: {avg_mse:.6f}, Accuracy: {accuracy:.4f}\")\n",
    "    return avg_mse, accuracy\n",
    "\n",
    "##############################################\n",
    "# 데이터 로드 및 전처리 (업비트 OHLC 값 사용: close는 원본값을 타깃으로)\n",
    "##############################################\n",
    "data = pd.read_csv(\"ETH_upbit_KRW_min5_0309.csv\", index_col=0)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data = data[['open', 'high', 'low', 'close']]\n",
    "\n",
    "# 각 OHLC에 대해 rolling minmax scaling 적용 후 scaled 컬럼 생성\n",
    "for feature in ['open', 'high', 'low', 'close']:\n",
    "    data[feature + '_scaled'] = rolling_minmax_scale(data[feature], window=24)\n",
    "data = data.dropna()\n",
    "\n",
    "# one-hot 인코딩: _scaled 컬럼 대상 (각 100구간 → 총 400차원)\n",
    "features_to_bin = ['open_scaled', 'high_scaled', 'low_scaled', 'close_scaled']\n",
    "data = bin_and_encode(data, features_to_bin, bins=100, drop_original=True)\n",
    "\n",
    "# 타깃: close_target은 원본 close 값을 그대로 사용\n",
    "data['close_target'] = data['close']\n",
    "data = data.dropna()\n",
    "\n",
    "# 최종 입력: '_scaled_Bin_'가 포함된 열들만 선택\n",
    "final_input_columns = [col for col in data.columns if '_scaled_Bin_' in col]\n",
    "final_target_column = ['close_target']\n",
    "\n",
    "data_input = data[final_input_columns]\n",
    "data_target = data[final_target_column]\n",
    "\n",
    "##############################################\n",
    "# 실제 거래를 위한 업비트 관련 함수 (모델 예측 기반)\n",
    "##############################################\n",
    "def get_model_prediction():\n",
    "    \"\"\"\n",
    "    pyupbit로 최근 50개의 5분봉 데이터를 가져와 전처리한 후,\n",
    "    마지막 lookback 개 봉을 diffusion model의 조건으로 사용하여\n",
    "    reverse diffusion sampling을 통해 다음 5분봉의 close (continuous) 값을 예측하고,\n",
    "    이전 close와 비교하여 상승(1) 또는 하락(-1) 방향과 예측 변화율을 반환.\n",
    "    \"\"\"\n",
    "    df = pyupbit.get_ohlcv(ticker, interval=\"minute5\", count=50)\n",
    "    if df is None or len(df) < lookback:\n",
    "        notify(\"예측에 충분한 데이터가 없습니다.\")\n",
    "        return None, None\n",
    "    ohlc_features = ['open', 'high', 'low', 'close']\n",
    "    for feature in ohlc_features:\n",
    "        df[feature] = rolling_minmax_scale(df[feature], window=24)\n",
    "    df_processed = bin_and_encode(df.copy(), ohlc_features, bins=100, drop_original=True)\n",
    "    final_input_columns = [col for col in df_processed.columns if '_Bin_' in col]\n",
    "    if len(df_processed) < lookback:\n",
    "        notify(\"lookback 데이터가 부족합니다.\")\n",
    "        return None, None\n",
    "    input_seq = df_processed[final_input_columns].iloc[-lookback:]\n",
    "    x = torch.tensor(input_seq.values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    # 이전 close (거래 평가용)\n",
    "    prev_close = df['close'].iloc[-2]\n",
    "    with torch.no_grad():\n",
    "        predicted_close = model.sample(x, device).item()  # 예측된 next close (continuous)\n",
    "        notify(\"디버그: predicted_close = \" + str(predicted_close))\n",
    "        # 변화율 계산\n",
    "        pct_change = (predicted_close - prev_close) / prev_close\n",
    "        # hold: 변화율이 ±0.1% 이내이면\n",
    "        if abs(pct_change) < 0.001:\n",
    "            decision = 0  # hold\n",
    "        else:\n",
    "            decision = 1 if pct_change > 0 else -1\n",
    "    return decision, pct_change\n",
    "\n",
    "def trade_decision():\n",
    "    decision, pct_change = get_model_prediction()\n",
    "    if decision is None:\n",
    "        return\n",
    "    entry_price = pyupbit.get_current_price(ticker)\n",
    "    if entry_price is None:\n",
    "        notify(\"현재가를 조회하지 못했습니다.\")\n",
    "        return\n",
    "    # hold 조건: 변화율이 ±0.1% 이내이면 거래를 진행하지 않음.\n",
    "    if decision == 0:\n",
    "        notify(\"예측 변화율이 미미하여 거래를 진행하지 않습니다 (Hold).\")\n",
    "        return\n",
    "    # 거래 비율은 예측 변화율의 절대값에 비례 (최대 20% 사용)\n",
    "    max_trade_fraction = 0.2\n",
    "    trade_fraction = min(max_trade_fraction, max_trade_fraction * abs(pct_change) * 10)  # 조정 인자\n",
    "    if decision > 0:\n",
    "        # 상승 예측: 매수\n",
    "        krw_balance = upbit.get_balance(\"KRW\")\n",
    "        if krw_balance is None or krw_balance < 5000:\n",
    "            notify(\"매수할 충분한 KRW 잔고가 없습니다.\")\n",
    "            return\n",
    "        trade_amount = krw_balance * trade_fraction\n",
    "        notify(f\"[진입] 상승 예측: 변화율 {pct_change*100:.2f}% → KRW 잔고의 {trade_fraction*100:.1f}% ({trade_amount:.0f} KRW)로 매수, 진입가: {entry_price:.2f}\")\n",
    "        upbit.buy_market_order(ticker, trade_amount)\n",
    "    else:\n",
    "        # 하락 예측: 매도\n",
    "        coin = ticker.split(\"-\")[1]\n",
    "        coin_balance = upbit.get_balance(coin)\n",
    "        if coin_balance is None or coin_balance <= 0:\n",
    "            notify(\"매도할 보유 코인이 없습니다.\")\n",
    "            return\n",
    "        trade_amount = coin_balance * trade_fraction\n",
    "        notify(f\"[진입] 하락 예측: 변화율 {pct_change*100:.2f}% → 보유 코인의 {trade_fraction*100:.1f}% ({trade_amount:.4f} 개) 매도, 진입가: {entry_price:.2f}\")\n",
    "        upbit.sell_market_order(ticker, trade_amount)\n",
    "\n",
    "##############################################\n",
    "# 거래 결과 처리 함수 (청산 시점에 거래 결과 계산)\n",
    "##############################################\n",
    "def process_pending_trade():\n",
    "    global pending_trade, stats\n",
    "    if pending_trade is None:\n",
    "        return\n",
    "    exit_price = pyupbit.get_current_price(ticker)\n",
    "    if exit_price is None:\n",
    "        notify(\"청산 가격을 조회하지 못했습니다.\")\n",
    "        return\n",
    "    direction = pending_trade['direction']\n",
    "    entry_price = pending_trade['entry_price']\n",
    "    fee = 0.0005\n",
    "    if direction == 1:  # Long 거래\n",
    "        fraction = pending_trade.get('trade_fraction', 0.2)\n",
    "        effective_factor = (exit_price * (1 - fee)) / (entry_price * (1 + fee))\n",
    "        trade_return = 1 + fraction * (effective_factor - 1)\n",
    "        trade_type = \"Long\"\n",
    "        outcome = \"Hit\" if exit_price > entry_price else \"Miss\"\n",
    "    else:  # Short 거래\n",
    "        fraction = pending_trade.get('trade_fraction', 0.2)\n",
    "        effective_factor = (entry_price * (1 - fee)) / (exit_price * (1 + fee))\n",
    "        trade_return = 1 + fraction * (effective_factor - 1)\n",
    "        trade_type = \"Short\"\n",
    "        outcome = \"Hit\" if exit_price <= entry_price else \"Miss\"\n",
    "    \n",
    "    stats['total_trades'] += 1\n",
    "    if outcome == \"Hit\":\n",
    "        stats['win_count'] += 1\n",
    "    stats['cumulative_return'] *= trade_return\n",
    "    stats['trade_returns'].append(trade_return)\n",
    "    quantity = pending_trade.get('quantity', 0)\n",
    "    notify(f\"[청산] {trade_type} 거래 - 진입가: {entry_price:.2f}, 청산가: {exit_price:.2f}, 거래 수량: {quantity:.4f}, 수익률: {trade_return:.4f} ({outcome})\")\n",
    "    hit_ratio = stats['win_count'] / stats['total_trades'] if stats['total_trades'] > 0 else 0\n",
    "    notify(f\"거래 횟수: {stats['total_trades']}, Hit Ratio: {hit_ratio:.2%}, 누적 수익률: {stats['cumulative_return']:.4f}\\n\")\n",
    "    pending_trade = None\n",
    "\n",
    "##############################################\n",
    "# 글로벌 변수 (진행 중 거래 및 통계)\n",
    "##############################################\n",
    "pending_trade = None\n",
    "stats = {\n",
    "    'total_trades': 0,\n",
    "    'win_count': 0,\n",
    "    'cumulative_return': 1.0,\n",
    "    'trade_returns': []\n",
    "}\n",
    "\n",
    "##############################################\n",
    "# 메인 거래 루프: 새로운 5분봉 생성 시마다 거래 결정\n",
    "##############################################\n",
    "last_candle_time = None\n",
    "while True:\n",
    "    try:\n",
    "        df = pyupbit.get_ohlcv(ticker, interval=\"minute5\", count=1)\n",
    "        if df is not None and not df.empty:\n",
    "            current_candle_time = df.index[-1]\n",
    "            if last_candle_time is None or current_candle_time > last_candle_time:\n",
    "                if pending_trade is not None:\n",
    "                    process_pending_trade()\n",
    "                notify(f\"새로운 5분봉 생성: {current_candle_time}\")\n",
    "                trade_decision()\n",
    "                last_candle_time = current_candle_time\n",
    "        else:\n",
    "            notify(\"최신 5분봉 데이터를 불러오지 못했습니다.\")\n",
    "    except Exception as e:\n",
    "        notify(f\"에러 발생: {e}\")\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39coin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
