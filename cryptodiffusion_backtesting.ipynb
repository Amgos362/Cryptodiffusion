{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyupbit\n",
    "\n",
    "# --- 전처리 함수 ---\n",
    "def rolling_minmax_scale(series, window=3):\n",
    "    roll_min = series.rolling(window=window, min_periods=window).min()\n",
    "    roll_max = series.rolling(window=window, min_periods=window).max()\n",
    "    scaled = (series - roll_min) / ((roll_max - roll_min) + 1e-8)\n",
    "    scaled = scaled.replace([np.inf, -np.inf], np.nan)\n",
    "    scaled = scaled.fillna(1.0)\n",
    "    return scaled.clip(upper=1.0)\n",
    "\n",
    "def bin_and_encode(data, features, bins=100, drop_original=True):\n",
    "    for feature in features:\n",
    "        data[f'{feature}_Bin'] = pd.cut(data[feature], bins=bins, labels=False)\n",
    "        one_hot = pd.get_dummies(data[f'{feature}_Bin'], prefix=f'{feature}_Bin').astype(np.int32)\n",
    "        expected_columns = [f'{feature}_Bin_{i}' for i in range(bins)]\n",
    "        one_hot = one_hot.reindex(columns=expected_columns, fill_value=0)\n",
    "        data = pd.concat([data, one_hot], axis=1)\n",
    "        if drop_original:\n",
    "            data.drop(columns=[f'{feature}_Bin'], inplace=True)\n",
    "    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in numeric_cols:\n",
    "        data[col] = data[col].astype(np.float32)\n",
    "    return data\n",
    "\n",
    "# --- Diffusion Model 구성 ---\n",
    "class ConditionEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim):\n",
    "        super(ConditionEncoder, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim * lookback, condition_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(condition_dim, condition_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [batch, lookback, input_dim]\n",
    "        batch_size = x.size(0)\n",
    "        x = x.contiguous().view(batch_size, -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class DiffusionClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, lookback, condition_dim=128, num_timesteps=100, hidden_dim=128):\n",
    "        super(DiffusionClassifier, self).__init__()\n",
    "        self.num_timesteps = num_timesteps\n",
    "        # diffusion 스케줄 (선형 beta schedule)\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1 - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.register_buffer('betas', betas)\n",
    "        self.register_buffer('alphas', alphas)\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        \n",
    "        # 조건 인코더: 시계열 window를 임베딩\n",
    "        self.condition_encoder = ConditionEncoder(input_dim, lookback, condition_dim)\n",
    "        # timestep 임베딩\n",
    "        self.time_embedding = nn.Embedding(num_timesteps, hidden_dim)\n",
    "        # 노이즈 예측 네트워크\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(1 + condition_dim + hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_condition, y_noisy, t):\n",
    "        # x_condition: [batch, lookback, input_dim]\n",
    "        # y_noisy: [batch, 1]\n",
    "        # t: [batch]\n",
    "        cond = self.condition_encoder(x_condition)           # [batch, condition_dim]\n",
    "        t_emb = self.time_embedding(t)                         # [batch, hidden_dim]\n",
    "        inp = torch.cat([y_noisy, cond, t_emb], dim=1)          # [batch, 1 + condition_dim + hidden_dim]\n",
    "        predicted_noise = self.model(inp)                      # [batch, 1]\n",
    "        return predicted_noise\n",
    "    \n",
    "    def sample(self, x_condition, device):\n",
    "        \"\"\"\n",
    "        reverse diffusion 과정을 통해 조건 x_condition에 대해 예측값을 샘플링.\n",
    "        최종 출력은 continuous 값으로, 임계값 0.5를 기준으로 상승(1) 또는 하락(0) 결정.\n",
    "        \"\"\"\n",
    "        batch_size = x_condition.size(0)\n",
    "        y = torch.randn(batch_size, 1, device=device)\n",
    "        for t in reversed(range(self.num_timesteps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            predicted_noise = self.forward(x_condition, y, t_tensor)\n",
    "            alpha = self.alphas[t]\n",
    "            alpha_cumprod = self.alphas_cumprod[t]\n",
    "            beta = self.betas[t]\n",
    "            y = (1 / torch.sqrt(alpha)) * (y - (beta / torch.sqrt(1 - alpha_cumprod)) * predicted_noise)\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(y)\n",
    "                y = y + torch.sqrt(beta) * noise\n",
    "        return y\n",
    "\n",
    "# --- 모델 로드 ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# OHLC 4개 feature를 100구간으로 binning하므로 입력 차원은 4*100 = 400\n",
    "input_dim = 400\n",
    "lookback = 3  # 백테스트 시 사용할 lookback 기간 (5분봉 기준 3개)\n",
    "model = DiffusionClassifier(input_dim=input_dim, lookback=lookback, condition_dim=128, num_timesteps=100, hidden_dim=128).to(device)\n",
    "model_path = \"diffusion_model_experiment_14_3.pth\"  # 실제 학습된 모델 파일 경로로 수정\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# --- 백테스팅용 예측 함수 ---\n",
    "def get_prediction_from_window(df, idx, lookback, device):\n",
    "    \"\"\"\n",
    "    df: OHLC 데이터프레임 (open, high, low, close 컬럼 포함)\n",
    "    idx: 거래를 진행할 시점 (해당 인덱스의 캔들로 거래한다고 가정)\n",
    "    lookback: 입력으로 사용할 캔들 개수\n",
    "    \"\"\"\n",
    "    ohlc_features = ['open', 'high', 'low', 'close']\n",
    "    # 거래 전 lookback 캔들 선택\n",
    "    window_df = df.iloc[idx - lookback: idx].copy()\n",
    "    # 각 feature에 대해 rolling scaling 적용\n",
    "    for feature in ohlc_features:\n",
    "        window_df[feature] = rolling_minmax_scale(window_df[feature], window=lookback)\n",
    "    window_df = bin_and_encode(window_df, ohlc_features, bins=100, drop_original=True)\n",
    "    final_input_columns = [col for col in window_df.columns if '_Bin_' in col]\n",
    "    if len(final_input_columns) == 0:\n",
    "        return None\n",
    "    input_seq = window_df[final_input_columns].iloc[-lookback:]\n",
    "    x = torch.tensor(input_seq.values, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_cont = model.sample(x, device)\n",
    "        prediction = 1 if y_cont.item() >= 0.5 else 0\n",
    "    return prediction\n",
    "\n",
    "# --- 백테스팅 함수 ---\n",
    "def backtest_trading(df, model, lookback, device):\n",
    "    \"\"\"\n",
    "    df: 과거 OHLC 데이터 (open, high, low, close 컬럼)\n",
    "    모델을 통해 각 거래 시점의 예측에 따라 롱/숏 거래를 시뮬레이션.\n",
    "    롱: entry = open, exit = close, 수익률 = close/open\n",
    "    숏: entry = open, exit = close, 수익률 = open/close\n",
    "    각 거래별 승리 여부(hit ratio)는 수익률 > 1 인 경우로 판단.\n",
    "    누적 수익률은 모든 거래 수익률의 곱으로 계산.\n",
    "    \"\"\"\n",
    "    total_trades = 0\n",
    "    win_count = 0\n",
    "    cumulative_return = 1.0\n",
    "    trade_returns = []\n",
    "    predictions = []\n",
    "    \n",
    "    # 인덱스 lookback부터 시작 (각 거래 시점에 대해 이전 lookback 캔들 사용)\n",
    "    for i in range(lookback, len(df)):\n",
    "        prediction = get_prediction_from_window(df, i, lookback, device)\n",
    "        if prediction is None:\n",
    "            continue\n",
    "        predictions.append(prediction)\n",
    "        trade_candle = df.iloc[i]\n",
    "        if prediction == 1:\n",
    "            # 예측이 상승이면 롱 거래: entry = open, exit = close\n",
    "            trade_ret = trade_candle['close'] / trade_candle['open']\n",
    "        else:\n",
    "            # 예측이 하락이면 숏 거래: entry = open, exit = close\n",
    "            trade_ret = trade_candle['open'] / trade_candle['close']\n",
    "        trade_returns.append(trade_ret)\n",
    "        total_trades += 1\n",
    "        cumulative_return *= trade_ret\n",
    "        # 거래 승리 판정: 수익률이 1보다 큰 경우 승리\n",
    "        if trade_ret > 1:\n",
    "            win_count += 1\n",
    "\n",
    "    hit_ratio = win_count / total_trades if total_trades > 0 else 0\n",
    "    return hit_ratio, cumulative_return, total_trades, trade_returns, predictions\n",
    "\n",
    "# --- 백테스팅 실행 ---\n",
    "# 예를 들어, CSV 파일에 저장된 과거 데이터 사용 (OHLC 데이터)\n",
    "data_path = \"ETH_upbit_KRW_min5_0309.csv\"  # 파일 경로에 맞게 수정\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df[['open', 'high', 'low', 'close']]\n",
    "\n",
    "# 백테스트 실행 (예: 전체 데이터에 대해)\n",
    "hit_ratio, cum_return, num_trades, trade_returns, preds = backtest_trading(df, model, lookback, device)\n",
    "print(\"총 거래 횟수:\", num_trades)\n",
    "print(\"Hit Ratio (승률): {:.2%}\".format(hit_ratio))\n",
    "print(\"누적 수익률:\", cum_return)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39coin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
